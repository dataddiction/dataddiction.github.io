# Deep learning: Application des m√©thodes d'apprentissages profonds


# Large CNN model for the CIFAR-10 Datasetimport numpyfrom keras.datasets import cifar10from keras.models import Sequentialfrom keras.layers import Densefrom keras.layers import Dropoutfrom keras.layers import Flattenfrom keras.constraints import maxnormfrom keras.optimizers import SGDfrom keras.layers.convolutional import Conv2Dfrom keras.layers.convolutional import MaxPooling2Dfrom keras.utils import np_utilsfrom keras import backend as KK.set_image_dim_ordering('th')# fix random seed for reproducibilityseed = 7numpy.random.seed(seed)# load data(X_train, y_train), (X_test, y_test) = cifar10.load_data()# normalize inputs from 0-255 to 0.0-1.0X_train = X_train.astype('float32')X_test = X_test.astype('float32')X_train = X_train / 255.0X_test = X_test / 255.0# one hot encode outputsy_train = np_utils.to_categorical(y_train)y_test = np_utils.to_categorical(y_test)num_classes = y_test.shape[1]# Create the modelmodel = Sequential()model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), activation='relu', padding='same'))model.add(Dropout(0.2))model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))model.add(Dropout(0.2))model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))model.add(Dropout(0.2))model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Flatten())model.add(Dropout(0.2))model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))model.add(Dropout(0.2))model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))model.add(Dropout(0.2))model.add(Dense(num_classes, activation='softmax'))# Compile modelepochs = 25lrate = 0.01decay = lrate/epochssgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])print(model.summary())# Fit the modelmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)# Final evaluation of the modelscores = model.evaluate(X_test, y_test, verbose=0)print("Accuracy: %.2f%%" % (scores[1]*100))
